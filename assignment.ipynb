{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "---------------\n",
    "\n",
    "For the first part of the practical assignment, we will use MapReduce paradigms to implement a word counting program. First, some setup and data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sc = pyspark.SparkContext(\"local[*]\", \"PUC Big Data workshop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the text file containing Shakespeare's famous Romeo & Juliet using a convenient PySpark function. This will automatically split the text file into separate lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some lines in the file are empty, we first filter those out; they do not contain words, so we don't need them! The `filter` operation will give us all lines with a length larger than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_lines = lines.filter(lambda line: len(line) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of non-empty sentences, we will split these sentences into single words. Since this is just an exercise, we will simply split the sentences on space characters; this will not give a perfect split, but it is good enough to use for the rest of the program. `flatMap` will make sure that we don't end up with nested lists and instead just give us one long list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = non_empty_lines.flatMap(lambda line: line.strip().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the words we ended up with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thy',\n",
       " 'tell',\n",
       " 'a',\n",
       " \"he's\",\n",
       " 'service.',\n",
       " 'Presents',\n",
       " 'Exit.',\n",
       " 'the',\n",
       " 'CLEOPATRA.',\n",
       " 'meet']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.takeSample(withReplacement=False, num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We loaded the text of Shakespeare's famous Romeo & Juliet, removed empty lines and split the remaining lines on spaces using the `flatMap` function. Displayed above are 25 random words sampled from the split text. As you can see, splitting the sentences on spaces does not result in a perfect separation of words but it will do for our purposes.\n",
    "\n",
    "------------------------\n",
    "\n",
    "Now, let's implement a simple word count! First, we will use the `map` operation to transform each word into a (word, 1) tuple as per the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_words = words.map(lambda word: (word, 1))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After annotating each word with the number 1, we can then perform the shuffle and a partial reduce step by using the `reduceByKey` operation. This will move all (word, 1) tuples with identical word values to the same worker node, and apply some function on them. In this case, since we are counting word occurrences, we simply add all the 1's together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = annotated_words.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to make the next steps easier, we first swap the positions of the words and their counts in the tuples so we end up with (count, word) instead of (word, count). This makes the count the key of the item, and will allow us to sort by key to see which words are most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = word_counts.map(lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the tuples by count in descending order, putting the most frequent words at the beginning of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_word_counts = word_counts.sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Let's look at the top 10 most frequent words in Romeo & Juliet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : 23178  occurrences\n",
      "I   : 19540  occurrences\n",
      "and : 18218  occurrences\n",
      "to  : 15592  occurrences\n",
      "of  : 15503  occurrences\n",
      "a   : 12513  occurrences\n",
      "my  : 10823  occurrences\n",
      "in  : 9564   occurrences\n",
      "you : 9058   occurrences\n",
      "is  : 7829   occurrences\n"
     ]
    }
   ],
   "source": [
    "for (count, word) in sorted_word_counts.take(10):\n",
    "    print(f\"{word:<4}: {count:<6} occurrences\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
